import {
  limitOpenAIMessagesToTokenCount,
  maxTokensForOpenAIModel
} from "./chunk-P7GKPATA.mjs";

// src/lib/openai-adapter.ts
import OpenAI from "openai";
var DEFAULT_MODEL = "gpt-4-1106-preview";
var OpenAIAdapter = class {
  constructor(params) {
    this.model = DEFAULT_MODEL;
    this._openai = (params == null ? void 0 : params.openai) || new OpenAI({});
    if (params == null ? void 0 : params.model) {
      this.model = params.model;
    }
  }
  get openai() {
    return this._openai;
  }
  async getResponse(forwardedProps) {
    forwardedProps = { ...forwardedProps };
    if (forwardedProps.tools && forwardedProps.tools.length === 0) {
      delete forwardedProps.tools;
    }
    const messages = limitOpenAIMessagesToTokenCount(
      forwardedProps.messages || [],
      forwardedProps.tools || [],
      maxTokensForOpenAIModel(forwardedProps.model || this.model)
    );
    const stream = this.openai.beta.chat.completions.stream({
      model: this.model,
      ...forwardedProps,
      stream: true,
      messages
    }).toReadableStream();
    return { stream };
  }
};

export {
  OpenAIAdapter
};
//# sourceMappingURL=chunk-Y5ERRBLZ.mjs.map